{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile(samples,q,dim=1):\n",
    "    return torch.quantile(samples,q,dim=dim).cpu().numpy()\n",
    "\n",
    "def normalize_std(record):\n",
    "    mean_val = np.mean(record, axis=-1)\n",
    "    std_val = np.std(record, axis=-1)\n",
    "    normalized_data = (record.T - mean_val) / std_val\n",
    "\n",
    "    return normalized_data.T\n",
    "\n",
    "def normalize_minmax(record):\n",
    "    min_val = np.min(record, axis=-1)\n",
    "    max_val = np.max(record, axis=-1)\n",
    "    normalized_data = (record.T - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized_data.T\n",
    "\n",
    "def JS_divergence(p, q):\n",
    "    p = (p - np.min(p))/(np.max(p)-np.min(p))\n",
    "    q = (q - np.min(q))/(np.max(q)-np.min(q))\n",
    "    M = (p + q) / 2\n",
    "    return 0.5 * entropy(p, M, base=2) + 0.5 * entropy(q, M, base=2)\n",
    "\n",
    "def total_variation_distance(p, q):\n",
    "    if len(p) != len(q):\n",
    "        raise ValueError(\"两个序列的长度必须相同\")\n",
    "\n",
    "    total_var_distance = 0\n",
    "    n = len(p)\n",
    "\n",
    "    for i in range(n):\n",
    "        total_var_distance += abs(p[i] - q[i]) / 2\n",
    "    total_var_distance /= n\n",
    "\n",
    "    return total_var_distance\n",
    "\n",
    "def mean_squared_error(p, q):\n",
    "    if len(p) != len(q):\n",
    "        raise ValueError(\"两个序列的长度必须相同\")\n",
    "\n",
    "    mse = sum((pi - qi) ** 2 for pi, qi in zip(p, q)) / len(p)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "def mean_absolute_error(p, q):\n",
    "    if len(p) != len(q):\n",
    "        raise ValueError(\"两个序列的长度必须相同\")\n",
    "\n",
    "    mae = sum(abs(pi - qi) for pi, qi in zip(p, q)) / len(p)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "def get_CRPS(data, G):\n",
    "    N, L = data.shape\n",
    "    crps_values = []\n",
    "\n",
    "    for i in range(N):\n",
    "        true_cdf = compute_cdf(data[i, :])\n",
    "        gen_cdf = compute_cdf(G[i, :])\n",
    "        \n",
    "        if np.max(gen_cdf)>2.5:\n",
    "            continue\n",
    "\n",
    "        crps_i = np.sum(np.square(true_cdf - gen_cdf))\n",
    "        crps_values.append(crps_i)\n",
    "\n",
    "    mean_crps = np.mean(crps_values)\n",
    "    return mean_crps\n",
    "\n",
    "def compute_cdf(values):\n",
    "    # 使用SciPy中的norm库估计累积分布函数\n",
    "    cdf_values = norm.cdf(values)\n",
    "    return cdf_values\n",
    "\n",
    "def new_CRPS(target, sample):\n",
    "    true_cdf = compute_cdf(target)\n",
    "    gen_cdf = compute_cdf(sample)\n",
    "        \n",
    "    crps_i = np.sum(np.square(true_cdf - gen_cdf))\n",
    "    return crps_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'value' #choose 'healthcare', 'airquality' or 'value'\n",
    "datafolder = 'shiqu_0523_202605-E700N560' # set the folder name\n",
    "nsample = 10 # number of generated sample\n",
    "\n",
    "path = './save/'+datafolder+'/generated_outputs_nsample' + str(nsample) + '.pk' \n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    samples, all_target, all_observed_time, scaler, mean_scaler = pickle.load( f)\n",
    "\n",
    "samples_np = []\n",
    "for i in range(nsample):\n",
    "    samples_np.append(samples[:, i, :, 0].cpu().numpy())\n",
    "samples_np = np.array(samples_np)\n",
    "all_target_np = all_target[:, :, 0].cpu().numpy()\n",
    "\n",
    "L = samples_np.shape[-1] #time length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_result = './save/'+datafolder+'/result_nsample' + str(nsample) + '.pk' \n",
    "\n",
    "with open(path_result, 'rb') as f:\n",
    "    JS_div, JS_one_div, tv_distance, CRPS, _ = pickle.load(f)\n",
    "\n",
    "print(\"JS_div = \", JS_div, \"\\nJS_one_div = \", JS_one_div, \"\\ntv_distance = \", tv_distance, \"\\nCRPS = \", CRPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all_target_np.shape: \", all_target_np.shape)\n",
    "print(\"samples_np.shape: \", samples_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_target_np = normalize_std(all_target_np)\n",
    "# for i in range(nsample):\n",
    "#     samples_np_one = samples_np[i]\n",
    "#     samples_np[i] = normalize_std(samples_np_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**指标计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JS = [0 for i in range(nsample)]\n",
    "TV_avg = [0 for i in range(nsample)]\n",
    "MSE = [0 for i in range(nsample)]\n",
    "MAE = [0 for i in range(nsample)]\n",
    "CRPS = [0 for i in range(nsample)]\n",
    "\n",
    "metrics_target = all_target_np[:, 72:96]\n",
    "metrics_sample = samples_np[:, :, 72:96]\n",
    "\n",
    "N = metrics_sample.shape[1]\n",
    "for k in range(nsample):\n",
    "    n = N\n",
    "    for i in range(N):\n",
    "        # if np.std(metrics_sample[k, i] - metrics_target[i]) > 1:\n",
    "        #     n = n - 1\n",
    "        #     continue\n",
    "        JS[k] += JS_divergence(metrics_target[i], metrics_sample[k, i])\n",
    "        TV_avg[k] += total_variation_distance(metrics_target[i], metrics_sample[k, i])\n",
    "        MSE[k] += mean_squared_error(metrics_target[i], metrics_sample[k, i])\n",
    "        MAE[k] += mean_absolute_error(metrics_target[i], metrics_sample[k, i])\n",
    "        CRPS[k] += new_CRPS(metrics_target[i], metrics_sample[k, i])\n",
    "    JS[k] = JS[k]/n\n",
    "    TV_avg[k] = TV_avg[k]/n\n",
    "    MSE[k] = MSE[k]/n\n",
    "    MAE[k] = MAE[k]/n\n",
    "    CRPS[k] = CRPS[k]/n\n",
    "\n",
    "print(f'JS-div: {np.mean(JS):.4g}\\t FLU: {np.max([np.max(JS)-np.mean(JS), np.mean(JS)-np.min(JS)]):.4f}')\n",
    "print(f'Avg-TV: {np.mean(TV_avg):.4g} \\t FLU: {np.max([np.max(TV_avg)-np.mean(TV_avg), np.mean(TV_avg)-np.min(TV_avg)]):.4f}')\n",
    "print(f'MSE: {np.mean(MSE):.4g} \\t FLU: {np.max([np.max(MSE)-np.mean(MSE), np.mean(MSE)-np.min(MSE)]):.4f}')\n",
    "print(f'MAE: {np.mean(MAE):.4g} \\t FLU: {np.max([np.max(MAE)-np.mean(MAE), np.mean(MAE)-np.min(MAE)]):.4f}')\n",
    "print(f'CRPS: {np.mean(CRPS):.4g} \\t FLU: {np.max([np.max(CRPS)-np.mean(CRPS), np.mean(CRPS)-np.min(CRPS)]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JS = np.array(JS)\n",
    "TV_avg = np.array(TV_avg)\n",
    "MAE = np.array(MAE)\n",
    "CRPS = np.array(CRPS)\n",
    "\n",
    "with open('shiqu_main.pk', \"wb\") as f:\n",
    "    pickle.dump([JS, TV_avg, MAE, CRPS], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**平均图像**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataind = 2  # change to visualize a different time-series sample\n",
    "\n",
    "target_avg = np.mean(all_target_np, axis = 0)\n",
    "sample_avg = np.mean(np.mean(samples_np, axis=1), axis = 0)\n",
    "\n",
    "JS = JS_divergence(target_avg, sample_avg)\n",
    "TV_avg = total_variation_distance(target_avg, sample_avg)\n",
    "MSE = mean_squared_error(target_avg, sample_avg)\n",
    "# CRPS = get_CRPS(all_target_np, np.mean(samples_np, axis=0)) \n",
    "CRPS = get_CRPS(target_avg.reshape(1, -1), sample_avg.reshape(1, -1))\n",
    "\n",
    "# plt.rcParams[\"font.size\"] = 16\n",
    "plt.figure(figsize=(5, 4), dpi=160)\n",
    "\n",
    "df_target = pd.DataFrame({\"x\": np.arange(0, L), \"val\": target_avg})\n",
    "plt.plot(df_target.x, df_target.val, color='b', linestyle='solid', label='real data', linewidth=0.8)\n",
    "\n",
    "df_sample = pd.DataFrame({\"x\": np.arange(0, L), \"val\": sample_avg})\n",
    "plt.plot(df_sample.x, df_sample.val, color='g', linestyle='solid', label='generated data', linewidth=0.8)\n",
    "\n",
    "plt.xlabel('time')\n",
    "# plt.ylabel('Normalized traffic value')\n",
    "plt.ylabel('Unnormalized traffic value')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'JS-div: {JS}')\n",
    "print(f'Avg-TV: {TV_avg}')\n",
    "print(f'MSE: {MSE}')\n",
    "print(f'CRPS: {CRPS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**单个图像**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataind = 2  # change to visualize a different time-series sample\n",
    "num_show = 10\n",
    "\n",
    "for i in range(num_show):\n",
    "    plt.figure(figsize=(25, 6), dpi=160)\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.22)  # 调整子图之间的垂直和水平间距\n",
    "    Add = 0\n",
    "    for j in range(nsample):        \n",
    "        if j < nsample//2:\n",
    "            plt.subplot(2, nsample//2, j + 1)\n",
    "        else:\n",
    "            plt.subplot(2, nsample//2, j + 1)\n",
    "                \n",
    "        df_target = pd.DataFrame({\"x\": np.arange(0, L), \"val\": all_target_np[i + Add]})\n",
    "        plt.plot(df_target.x,\n",
    "                df_target.val,\n",
    "                color='b',\n",
    "                linestyle='solid',\n",
    "                label='real data[' + str(i + Add) + ']',\n",
    "                linewidth=1.2)\n",
    "\n",
    "        df_sample = pd.DataFrame({\"x\": np.arange(0, L), \"val\": samples_np[j, i + Add]})\n",
    "        plt.plot(df_sample.x,\n",
    "                df_sample.val,\n",
    "                color='g',\n",
    "                linestyle='solid',\n",
    "                label='generated data[' + str(i + Add) + ']',\n",
    "                linewidth=1.2)\n",
    "\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('Normalized traffic value', fontsize=10)\n",
    "\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataind = 2  # change to visualize a different time-series sample\n",
    "real_num = 39\n",
    "\n",
    "plt.figure(figsize=(25, 6), dpi=160)\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.22)  # 调整子图之间的垂直和水平间距\n",
    "for j in range(nsample):        \n",
    "    if j < nsample//2:\n",
    "        plt.subplot(2, nsample//2, j + 1)\n",
    "    else:\n",
    "        plt.subplot(2, nsample//2, j + 1)\n",
    "            \n",
    "    df_target = pd.DataFrame({\"x\": np.arange(0, L), \"val\": all_target_np[real_num]})\n",
    "    plt.plot(df_target.x,\n",
    "            df_target.val,\n",
    "            color='b',\n",
    "            linestyle='solid',\n",
    "            label='real data',\n",
    "            linewidth=1.8)\n",
    "\n",
    "    df_sample = pd.DataFrame({\"x\": np.arange(0, L), \"val\": samples_np[j, real_num]})\n",
    "    plt.plot(df_sample.x,\n",
    "            df_sample.val,\n",
    "            color='g',\n",
    "            linestyle='solid',\n",
    "            label='generated data',\n",
    "            linewidth=1.8)\n",
    "\n",
    "    plt.xlabel('time (hours)')\n",
    "    plt.ylabel('Normalized traffic value')\n",
    "\n",
    "    plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
